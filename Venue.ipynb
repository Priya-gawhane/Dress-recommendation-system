{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816506f3-fb44-432e-b96d-ddcde7640514",
   "metadata": {},
   "source": [
    "Dress recomendation system based on the venue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131e0b3-d7da-4712-a866-b6bcadc05944",
   "metadata": {},
   "source": [
    "Installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19170b9e-b22a-422b-b050-b01118bb90e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     -------------------------------------- 347.8/347.8 KB 4.3 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "     ---------------------------------------- 15.9/15.9 MB 4.7 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     -------------------------------------- 509.2/509.2 KB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5174323e-f2b1-4a8b-ba3a-a9d42318a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abec1c21-7f93-4421-9cce-3eee15b30f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     -------------------------------------- 294.9/294.9 KB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (2.0.2)\n",
      "Collecting matplotlib!=3.6.1,>=3.4\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 KB 3.0 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.58.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "     -------------------------------------- 111.1/111.1 KB 6.3 MB/s eta 0:00:00\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "     -------------------------------------- 211.8/211.8 KB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.58.0 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.2.1 pyparsing-3.2.3 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78acf303-17a3-4986-8e14-9df44f893c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1b2212-69f7-434f-9ede-1cfb81aeed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "     ---------------------------------------- 11.2/11.2 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 46.2/46.2 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "     -------------------------------------- 307.7/307.7 KB 9.6 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.0 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0461d67-f0b6-4494-9e5f-f63a7ecd9077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (22.0.4)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 6.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.4\n",
      "    Uninstalling pip-22.0.4:\n",
      "      Successfully uninstalled pip-22.0.4\n",
      "Successfully installed pip-25.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf37ed40-9aae-4f60-a26b-79367d8c94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67754c4-8372-4009-a30c-573d2a9573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "def load_data():\n",
    "    clothing_items = pd.read_csv(\"clothing_items_csv.txt\")\n",
    "    venues = pd.read_csv(\"venues_csv.txt\")\n",
    "    compatibility_matrix = pd.read_csv(\"compatibility_matrix_csv.txt\")\n",
    "    outfit_combinations = pd.read_csv(\"outfit_combinations_csv.txt\")\n",
    "    recommendation_rules = pd.read_csv(\"recommendation_rules_csv.txt\")\n",
    "    image_references = pd.read_csv(\"image_references_csv.txt\")\n",
    "    \n",
    "    # Parse item lists in outfit combinations\n",
    "    outfit_combinations['items_list'] = outfit_combinations['items'].apply(lambda x: x.split(','))\n",
    "    outfit_combinations['venue_ids_list'] = outfit_combinations['venue_ids'].apply(lambda x: x.split(','))\n",
    "    \n",
    "    return clothing_items, venues, compatibility_matrix, outfit_combinations, recommendation_rules, image_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1159428c-fc43-49c0-8441-295b24eb7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(clothing_items, venues, compatibility_matrix):\n",
    "    \"\"\"Explore the data to understand relationships\"\"\"\n",
    "    # Distribution of formality levels in clothing items\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='formality_level', data=clothing_items)\n",
    "    plt.title('Distribution of Clothing Formality Levels')\n",
    "    plt.savefig('clothing_formality_dist.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Distribution of formality levels in venues\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='formality_level', data=venues)\n",
    "    plt.title('Distribution of Venue Formality Levels')\n",
    "    plt.savefig('venue_formality_dist.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Heatmap of compatibility scores\n",
    "    pivot_comp = compatibility_matrix.pivot_table(\n",
    "        index='venue_id', \n",
    "        columns='item_id', \n",
    "        values='appropriateness_score', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_comp, cmap='YlGnBu', annot=True, fmt='.1f')\n",
    "    plt.title('Venue-Item Compatibility Scores')\n",
    "    plt.savefig('compatibility_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return pivot_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a656050d-5d7d-46cf-a8de-6a019022c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(clothing_items, venues):\n",
    "    \"\"\"Transform categorical features into numeric representations\"\"\"\n",
    "    # For clothing items\n",
    "    cat_features_items = ['category', 'color', 'pattern', 'material', 'season', 'gender_category']\n",
    "    enc_items = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    encoded_features_items = enc_items.fit_transform(clothing_items[cat_features_items])\n",
    "    encoded_df_items = pd.DataFrame(encoded_features_items, \n",
    "                                   columns=enc_items.get_feature_names_out(cat_features_items))\n",
    "    \n",
    "    # Add formality level as a numeric feature\n",
    "    encoded_df_items['formality_level'] = clothing_items['formality_level']\n",
    "    \n",
    "    # For venues\n",
    "    cat_features_venues = ['typical_weather', 'time_of_day']\n",
    "    enc_venues = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    encoded_features_venues = enc_venues.fit_transform(venues[cat_features_venues])\n",
    "    encoded_df_venues = pd.DataFrame(encoded_features_venues, \n",
    "                                    columns=enc_venues.get_feature_names_out(cat_features_venues))\n",
    "    \n",
    "    # Add formality level as a numeric feature\n",
    "    encoded_df_venues['formality_level'] = venues['formality_level']\n",
    "    \n",
    "    return encoded_df_items, encoded_df_venues, enc_items, enc_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c477dd-bd7f-4948-8b18-1d741912611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compatibility_model(compatibility_matrix, clothing_items, venues, encoded_df_items, encoded_df_venues):\n",
    "    \"\"\"Build a random forest model to predict compatibility scores\"\"\"\n",
    "    # Prepare training data\n",
    "    training_data = []\n",
    "    \n",
    "    for _, row in compatibility_matrix.iterrows():\n",
    "        venue_id = row['venue_id']\n",
    "        item_id = row['item_id']\n",
    "        score = row['appropriateness_score']\n",
    "        \n",
    "        # Get venue features\n",
    "        venue_idx = venues[venues['venue_id'] == venue_id].index[0]\n",
    "        venue_features = encoded_df_venues.iloc[venue_idx].values\n",
    "        \n",
    "        # Get item features\n",
    "        item_idx = clothing_items[clothing_items['item_id'] == item_id].index[0]\n",
    "        item_features = encoded_df_items.iloc[item_idx].values\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([venue_features, item_features])\n",
    "        training_data.append((combined_features, score))\n",
    "    \n",
    "    # Split into X and y\n",
    "    X = np.array([item[0] for item in training_data])\n",
    "    y = np.array([item[1] for item in training_data])\n",
    "    \n",
    "    # Train a random forest regressor\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85eec0e9-c824-4387-825c-73d7f4bfaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_outfit_recommender(clothing_items, encoded_df_items, outfit_combinations):\n",
    "    \"\"\"Build a nearest neighbors model for outfit recommendations\"\"\"\n",
    "    # Create a mapping from item_id to its features\n",
    "    item_features_map = {}\n",
    "    for idx, row in clothing_items.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        item_features = encoded_df_items.iloc[idx].values\n",
    "        item_features_map[item_id] = item_features\n",
    "    \n",
    "    # Create outfit feature vectors by averaging item features\n",
    "    outfit_features = []\n",
    "    outfit_ids = []\n",
    "    \n",
    "    for _, row in outfit_combinations.iterrows():\n",
    "        outfit_id = row['outfit_id']\n",
    "        items_list = row['items_list']\n",
    "        \n",
    "        # Compute average features across all items in the outfit\n",
    "        item_features_list = [item_features_map[item_id] for item_id in items_list if item_id in item_features_map]\n",
    "        if item_features_list:\n",
    "            avg_features = np.mean(item_features_list, axis=0)\n",
    "            outfit_features.append(avg_features)\n",
    "            outfit_ids.append(outfit_id)\n",
    "    \n",
    "    # Build a nearest neighbors model\n",
    "    nn_model = NearestNeighbors(n_neighbors=3, algorithm='ball_tree')\n",
    "    nn_model.fit(outfit_features)\n",
    "    \n",
    "    return nn_model, outfit_features, outfit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a165242-3efe-451e-8ba0-6a81bc41e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, encoded_df_items, encoded_df_venues):\n",
    "    \"\"\"Analyze feature importance for the compatibility model\"\"\"\n",
    "    feature_names = list(encoded_df_venues.columns) + list(encoded_df_items.columns)\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Feature Importances for Outfit Compatibility')\n",
    "    plt.bar(range(len(indices[:15])), importances[indices[:15]], align='center')\n",
    "    plt.xticks(range(len(indices[:15])), [feature_names[i] for i in indices[:15]], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return [(feature_names[i], importances[i]) for i in indices[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d28fe81-813a-417c-a24a-1f250c6635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_outfit_for_venue(venue_id, venues, clothing_items, model, outfit_combinations, \n",
    "                              nn_model, outfit_features, outfit_ids, encoded_df_venues, encoded_df_items,\n",
    "                              recommendation_rules):\n",
    "    \"\"\"Recommend outfits for a given venue\"\"\"\n",
    "    # Get venue information\n",
    "    venue_info = venues[venues['venue_id'] == venue_id].iloc[0]\n",
    "    venue_idx = venues[venues['venue_id'] == venue_id].index[0]\n",
    "    venue_features = encoded_df_venues.iloc[venue_idx].values\n",
    "    \n",
    "    print(f\"Recommendations for venue: {venue_info['venue_name']} (Formality Level: {venue_info['formality_level']})\")\n",
    "    \n",
    "    # 1. Direct outfit recommendations based on outfits marked for this venue\n",
    "    direct_outfits = outfit_combinations[outfit_combinations['venue_ids'].str.contains(venue_id)]\n",
    "    print(\"\\nPre-defined outfits for this venue:\")\n",
    "    if not direct_outfits.empty:\n",
    "        for _, outfit in direct_outfits.iterrows():\n",
    "            items_list = outfit['items_list']\n",
    "            item_names = [clothing_items[clothing_items['item_id'] == item_id]['item_name'].values[0] \n",
    "                         for item_id in items_list if item_id in clothing_items['item_id'].values]\n",
    "            print(f\"- {outfit['name']} (Score: {outfit['overall_score']}): {', '.join(item_names)}\")\n",
    "    else:\n",
    "        print(\"No pre-defined outfits found for this venue.\")\n",
    "    \n",
    "    # 2. Find similar outfits based on venue formality\n",
    "    # Create a query vector representing the venue's formality level\n",
    "    query_vector = np.zeros_like(outfit_features[0])\n",
    "    formality_idx = list(encoded_df_venues.columns).index('formality_level')\n",
    "    query_vector[formality_idx] = venue_info['formality_level']\n",
    "    \n",
    "    # Find nearest outfit neighbors\n",
    "    distances, indices = nn_model.kneighbors([query_vector])\n",
    "    \n",
    "    print(\"\\nRecommended outfits based on similarity to venue formality:\")\n",
    "    for idx in indices[0]:\n",
    "        outfit_id = outfit_ids[idx]\n",
    "        outfit = outfit_combinations[outfit_combinations['outfit_id'] == outfit_id].iloc[0]\n",
    "        items_list = outfit['items_list']\n",
    "        item_names = [clothing_items[clothing_items['item_id'] == item_id]['item_name'].values[0] \n",
    "                     for item_id in items_list if item_id in clothing_items['item_id'].values]\n",
    "        print(f\"- {outfit['name']} (Score: {outfit['overall_score']}): {', '.join(item_names)}\")\n",
    "    \n",
    "    # 3. Item-by-item compatibility check for top-rated individual items\n",
    "    compatible_items = []\n",
    "    \n",
    "    for idx, item in clothing_items.iterrows():\n",
    "        item_id = item['item_id']\n",
    "        item_features = encoded_df_items.iloc[idx].values\n",
    "        \n",
    "        # Combine venue and item features\n",
    "        combined_features = np.concatenate([venue_features, item_features])\n",
    "        \n",
    "        # Predict compatibility\n",
    "        score = model.predict([combined_features])[0]\n",
    "        compatible_items.append((item_id, score, item['item_name'], item['category']))\n",
    "    \n",
    "    # Sort by score and category\n",
    "    compatible_items.sort(key=lambda x: (-x[1], x[3]))\n",
    "    \n",
    "    # Group by category and show top item for each\n",
    "    categories = {}\n",
    "    for item in compatible_items:\n",
    "        if item[3] not in categories:\n",
    "            categories[item[3]] = item\n",
    "    \n",
    "    print(\"\\nRecommended individual items by category:\")\n",
    "    for category, item in categories.items():\n",
    "        print(f\"- {category}: {item[2]} (Compatibility Score: {item[1]})\")\n",
    "    \n",
    "    # 4. Check recommendation rules\n",
    "    print(\"\\nSpecial recommendations based on rules:\")\n",
    "    venue_rules = recommendation_rules[recommendation_rules['venue_id'] == venue_id]\n",
    "    if not venue_rules.empty:\n",
    "        for _, rule in venue_rules.iterrows():\n",
    "            inappropriate_id = rule['inappropriate_item_id']\n",
    "            inappropriate_name = clothing_items[clothing_items['item_id'] == inappropriate_id]['item_name'].values[0] if inappropriate_id else \"\"\n",
    "            \n",
    "            recommended_id = rule['recommended_item_id']\n",
    "            if pd.notna(recommended_id):\n",
    "                recommended_name = clothing_items[clothing_items['item_id'] == recommended_id]['item_name'].values[0]\n",
    "                print(f\"- {rule['recommendation_text']} (Replace {inappropriate_name} with {recommended_name})\")\n",
    "            else:\n",
    "                print(f\"- {rule['recommendation_text']}\")\n",
    "    else:\n",
    "        print(\"No specific rules found for this venue.\")\n",
    "\n",
    "def evaluate_model_accuracy(compatibility_matrix, clothing_items, venues, encoded_df_items, encoded_df_venues, model):\n",
    "    \"\"\"Evaluate the accuracy of the compatibility prediction model using cross-validation\"\"\"\n",
    "    from sklearn.model_selection import KFold, cross_val_score\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    \n",
    "    # Prepare data for evaluation\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _, row in compatibility_matrix.iterrows():\n",
    "        venue_id = row['venue_id']\n",
    "        item_id = row['item_id']\n",
    "        score = row['appropriateness_score']\n",
    "        \n",
    "        # Get venue features\n",
    "        venue_idx = venues[venues['venue_id'] == venue_id].index[0]\n",
    "        venue_features = encoded_df_venues.iloc[venue_idx].values\n",
    "        \n",
    "        # Get item features\n",
    "        item_idx = clothing_items[clothing_items['item_id'] == item_id].index[0]\n",
    "        item_features = encoded_df_items.iloc[item_idx].values\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([venue_features, item_features])\n",
    "        X.append(combined_features)\n",
    "        y.append(score)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\nModel Accuracy Evaluation:\")\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "    \n",
    "    # Generate predictions on the entire dataset for more detailed metrics\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Classification metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return cv_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b6c4cd8-4a4f-42f5-8b2b-cd0570965adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_new_venue(venue_description, formality_level, weather, time_of_day, \n",
    "                             venues, clothing_items, model, outfit_combinations, \n",
    "                             nn_model, outfit_features, outfit_ids, encoded_df_venues, encoded_df_items,\n",
    "                             recommendation_rules, enc_venues):\n",
    "    \"\"\"Test the model with a new venue not in the original dataset\"\"\"\n",
    "    # Create a new venue entry\n",
    "    new_venue_id = f\"V{len(venues) + 1:03d}\"\n",
    "    new_venue = pd.DataFrame({\n",
    "        'venue_id': [new_venue_id],\n",
    "        'venue_name': [venue_description],\n",
    "        'formality_level': [formality_level],\n",
    "        'description': [venue_description],\n",
    "        'typical_weather': [weather],\n",
    "        'time_of_day': [time_of_day]\n",
    "    })\n",
    "    \n",
    "    # Encode the new venue features\n",
    "    new_venue_features = pd.DataFrame({\n",
    "        'typical_weather': [weather],\n",
    "        'time_of_day': [time_of_day]\n",
    "    })\n",
    "    \n",
    "    # One-hot encode the categorical features\n",
    "    encoded_features = enc_venues.transform(new_venue_features)\n",
    "    encoded_new_venue = pd.DataFrame(\n",
    "        encoded_features, \n",
    "        columns=enc_venues.get_feature_names_out(['typical_weather', 'time_of_day'])\n",
    "    )\n",
    "    \n",
    "    # Add formality level\n",
    "    encoded_new_venue['formality_level'] = formality_level\n",
    "    \n",
    "    # Generate recommendations for the new venue\n",
    "    print(f\"\\nRecommendations for new venue: {venue_description}\")\n",
    "    print(f\"Formality Level: {formality_level}, Weather: {weather}, Time: {time_of_day}\")\n",
    "    \n",
    "    # Generate item recommendations\n",
    "    compatible_items = []\n",
    "    \n",
    "    for idx, item in clothing_items.iterrows():\n",
    "        item_id = item['item_id']\n",
    "        item_features = encoded_df_items.iloc[idx].values\n",
    "        \n",
    "        # Combine venue and item features\n",
    "        combined_features = np.concatenate([encoded_new_venue.iloc[0].values, item_features])\n",
    "        \n",
    "        # Predict compatibility\n",
    "        score = model.predict([combined_features])[0]\n",
    "        compatible_items.append((item_id, score, item['item_name'], item['category']))\n",
    "    \n",
    "    # Sort by score and category\n",
    "    compatible_items.sort(key=lambda x: (-x[1], x[3]))\n",
    "    \n",
    "    # Group by category and show top items\n",
    "    categories = {}\n",
    "    for item in compatible_items:\n",
    "        if item[3] not in categories:\n",
    "            categories[item[3]] = []\n",
    "        if len(categories[item[3]]) < 2:  # Get top 2 for each category\n",
    "            categories[item[3]].append(item)\n",
    "    \n",
    "    print(\"\\nTop recommended items by category:\")\n",
    "    for category, items in categories.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"- {item[2]} (Compatibility Score: {item[1]})\")\n",
    "    \n",
    "    # Create outfit recommendations by combining top items from different categories\n",
    "    print(\"\\nRecommended outfit combinations:\")\n",
    "    \n",
    "    # Try to construct an outfit with top items from different categories\n",
    "    outfit = []\n",
    "    required_categories = ['Top', 'Bottom', 'Footwear']\n",
    "    optional_categories = ['Outerwear', 'Suit', 'Dress']\n",
    "    \n",
    "    # Add required categories\n",
    "    for category in required_categories:\n",
    "        if category in categories and categories[category]:\n",
    "            top_item = categories[category][0]\n",
    "            outfit.append(top_item[2])\n",
    "    \n",
    "    # Add optional categories based on formality\n",
    "    if formality_level >= 4:  # For formal events\n",
    "        for category in optional_categories:\n",
    "            if category in categories and categories[category]:\n",
    "                if category == 'Dress' or category == 'Suit':  # These could replace Top+Bottom\n",
    "                    if len(outfit) >= 2:  # If we already added Top and Bottom\n",
    "                        outfit = [item for item in outfit if 'Top' not in item and 'Bottom' not in item]\n",
    "                    outfit.append(categories[category][0][2])\n",
    "                else:\n",
    "                    outfit.append(categories[category][0][2])\n",
    "    \n",
    "    print(f\"- Complete outfit: {', '.join(outfit)}\")\n",
    "    \n",
    "    # Return the compatibility scores for analysis\n",
    "    return compatible_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65afc55f-5beb-40ac-98b5-f41b5627f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    clothing_items, venues, compatibility_matrix, outfit_combinations, recommendation_rules, image_references = load_data()\n",
    "    \n",
    "    # Explore data\n",
    "    pivot_comp = explore_data(clothing_items, venues, compatibility_matrix)\n",
    "    \n",
    "    # Preprocess data\n",
    "    encoded_df_items, encoded_df_venues, enc_items, enc_venues = preprocess_data(clothing_items, venues)\n",
    "    \n",
    "    # Build models\n",
    "    compatibility_model = build_compatibility_model(compatibility_matrix, clothing_items, venues, encoded_df_items, encoded_df_venues)\n",
    "    nn_model, outfit_features, outfit_ids = build_outfit_recommender(clothing_items, encoded_df_items, outfit_combinations)\n",
    "    \n",
    "    # Evaluate model accuracy\n",
    "    accuracy = evaluate_model_accuracy(compatibility_matrix, clothing_items, venues, encoded_df_items, encoded_df_venues, compatibility_model)\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    top_features = feature_importance(compatibility_model, encoded_df_items, encoded_df_venues)\n",
    "    print(\"\\nTop features for compatibility:\")\n",
    "    for feature, importance in top_features:\n",
    "        print(f\"- {feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Example recommendations\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Get user input for existing venue\n",
    "    print(\"\\nAvailable venues:\")\n",
    "    for _, venue in venues.iterrows():\n",
    "        print(f\"- {venue['venue_id']}: {venue['venue_name']} ({venue['description']})\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1. Get recommendations for existing venue\")\n",
    "        print(\"2. Test with a new venue\")\n",
    "        print(\"3. Exit\")\n",
    "        \n",
    "        choice = input(\"Enter your choice (1-3): \")\n",
    "        \n",
    "        if choice == '1':\n",
    "            venue_id = input(\"\\nEnter venue ID for outfit recommendations (e.g. V001): \")\n",
    "            if venue_id in venues['venue_id'].values:\n",
    "                recommend_outfit_for_venue(venue_id, venues, clothing_items, compatibility_model, outfit_combinations, \n",
    "                                          nn_model, outfit_features, outfit_ids, encoded_df_venues, encoded_df_items,\n",
    "                                          recommendation_rules)\n",
    "            else:\n",
    "                print(\"Invalid venue ID. Please try again.\")\n",
    "        \n",
    "        elif choice == '2':\n",
    "            print(\"\\nEnter details for a new venue:\")\n",
    "            venue_name = input(\"Venue name/description: \")\n",
    "            \n",
    "            # Get formality level with validation\n",
    "            while True:\n",
    "                try:\n",
    "                    formality = int(input(\"Formality level (1-5, where 1 is casual and 5 is very formal): \"))\n",
    "                    if 1 <= formality <= 5:\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a value between 1 and 5.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number.\")\n",
    "            \n",
    "            # Weather options\n",
    "            print(\"\\nWeather options:\")\n",
    "            print(\"1. Indoor\")\n",
    "            print(\"2. Outdoor Sunny\")\n",
    "            print(\"3. Outdoor Variable\")\n",
    "            print(\"4. Indoor Dark\")\n",
    "            \n",
    "            weather_choice = input(\"Select weather (1-4): \")\n",
    "            weather_map = {\n",
    "                '1': 'Indoor', \n",
    "                '2': 'Outdoor Sunny', \n",
    "                '3': 'Outdoor Variable', \n",
    "                '4': 'Indoor Dark'\n",
    "            }\n",
    "            weather = weather_map.get(weather_choice, 'Indoor')\n",
    "            \n",
    "            # Time of day options\n",
    "            print(\"\\nTime of day options:\")\n",
    "            print(\"1. Daytime\")\n",
    "            print(\"2. Evening\")\n",
    "            print(\"3. Night\")\n",
    "            \n",
    "            time_choice = input(\"Select time of day (1-3): \")\n",
    "            time_map = {\n",
    "                '1': 'Daytime', \n",
    "                '2': 'Evening', \n",
    "                '3': 'Night'\n",
    "            }\n",
    "            time_of_day = time_map.get(time_choice, 'Daytime')\n",
    "            \n",
    "            # Test with new venue\n",
    "            test_model_with_new_venue(\n",
    "                venue_name, formality, weather, time_of_day,\n",
    "                venues, clothing_items, compatibility_model, outfit_combinations,\n",
    "                nn_model, outfit_features, outfit_ids, encoded_df_venues, encoded_df_items,\n",
    "                recommendation_rules, enc_venues\n",
    "            )\n",
    "        \n",
    "        elif choice == '3':\n",
    "            print(\"Exiting program.\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ad164-aaf0-405a-833e-3f98cc2be572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
